let popupPort = null;
let infoByTab = {};

import CONFIG from './config.js';

chrome.runtime.onConnect.addListener((port) => {
  if (port.name === 'popup') {
    console.log('ğŸ“ íŒì—… ì—°ê²°ë¨');
    popupPort = port;

    port.onDisconnect.addListener(() => {
      console.log('ğŸ“´ íŒì—… ì—°ê²° í•´ì œë¨');
      popupPort = null;
    });
  }
});

// ë°°ì¹˜ì— ì´ë¯¸ì§€ë¥¼ ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜
async function addImageToBatch(tabId, dataUrl) {
  if (!infoByTab[tabId]) {
    infoByTab[tabId] = {
      images: [],
      texts: '',
    }; // ê° íƒ­ì— ëŒ€í•´ ì´ˆê¸°í™”
  }

  infoByTab[tabId].images.push({
    image: { content: dataUrl.split(',')[1] },
    features: [{ type: 'TEXT_DETECTION' }],
  });

  if (infoByTab[tabId].images.length >= 16) {
    await processImageBatch(tabId);
  }
}

// ë°°ì¹˜ë¥¼ Vision APIë¡œ ë³´ë‚´ê³  ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜
async function processImageBatch(tabId) {
  if (infoByTab[tabId].images.length === 0) return;

  const endpoint = `https://vision.googleapis.com/v1/images:annotate?key=${CONFIG.GOOGLE_CLOUD_API_KEY}`;
  const requestBody = { requests: infoByTab[tabId].images };

  try {
    const response = await fetch(endpoint, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(requestBody),
    });

    const result = await response.json();

    (result.responses || []).forEach((response) => {
      const text = response?.textAnnotations?.[0]?.description || '';
      if (text) {
        infoByTab[tabId].texts += text + '\n';
      }
    });
    console.log('OCR ì„±ê³µ');
  } catch (error) {
    console.error('OCR ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜:', error);
  } finally {
    infoByTab[tabId].images = []; // ë°°ì¹˜ ì´ˆê¸°í™”
  }
}

// ë©”ì‹œì§€ ë¦¬ìŠ¤ë„ˆë¥¼ ì„¤ì •í•˜ì—¬ popup.js ë˜ëŠ” content scriptì—ì„œ ìš”ì²­ì„ ìˆ˜ì‹ 
chrome.runtime.onMessage.addListener((request, sender, sendResponse) => {
  if (request.action === 'processURL') {
    const url = request.url;

    chrome.tabs.update({ url }, (tab) => {
      chrome.tabs.onUpdated.addListener(function listener(tabId, changeInfo) {
        if (tabId === tab.id && changeInfo.status === 'complete') {
          chrome.tabs.sendMessage(tab.id, { action: 'startProcessing' });
          chrome.tabs.onUpdated.removeListener(listener);
          sendResponse({ status: 'url loading complete' });
        }
      });
    });
    return true;
  } else if (request.action === 'captureAndProcess') {
    const tabId = sender.tab.id;
    chrome.tabs.captureVisibleTab(null, { format: 'png' }, async (dataUrl) => {
      if (dataUrl) {
        await addImageToBatch(tabId, dataUrl);
        sendResponse({ status: 'capture complete' });
      } else {
        sendResponse({ status: 'capture failed' });
      }
    });
    return true;
  } else if (request.action === 'scrollComplete') {
    const tabId = sender.tab.id;
    (async () => {
      // ë‚¨ì€ ë°°ì¹˜ ì²˜ë¦¬
      await processImageBatch(tabId).then(() => {
        const fileName = generateFileName(sender.tab.url); // íŒŒì¼ëª… ìƒì„±
        const message = `OCR text saved to ${fileName}`;
        console.log('OCR text: ', infoByTab[tabId].texts);

        // workflow ê°€ ë“±ë¡ë˜ì—ˆë‹¤ë©´ ì „ë‹¬
        if (CONFIG.WORKFLOW_URL.trim()) {
          sendOCRResultToWorkflow(fileName, infoByTab[tabId].texts);
          console.log(message);
        }

        infoByTab[tabId].texts = ''; // ëˆ„ì  í…ìŠ¤íŠ¸ ì´ˆê¸°í™”

        // íŒì—…í™”ë©´ì— ì „ë‹¬
        if (popupPort) {
          popupPort.postMessage({ action: 'displayResult', message });
        }

        // content.js ì— ì „ë‹¬
        sendResponse({ message }); // OCR ê²°ê³¼ë¥¼ ì‘ë‹µìœ¼ë¡œ ë°˜í™˜
      });
    })();
    return true;
  } else if (request.action === 'progressUpdate') {
    if (popupPort) {
      popupPort.postMessage({
        action: 'progressUpdate',
        currentScrollIndex: request.currentScrollIndex,
        totalScrolls: request.totalScrolls,
      });
    }
    sendResponse({ status: 'progress updated' }); // ì‘ë‹µ ì¶”ê°€
    return true;
  }
});

function generateFileName(url) {
  const paths = new URL(url).pathname.split('/').slice(-3);
  return paths.join('_');
}

async function sendOCRResultToWorkflow(fileName, ocrText) {
  const now = new Date();
  const localDate = `${now.getFullYear()}-${String(now.getMonth() + 1).padStart(
    2,
    '0'
  )}-${String(now.getDate()).padStart(2, '0')} ${String(
    now.getHours()
  ).padStart(2, '0')}:${String(now.getMinutes()).padStart(2, '0')}:${String(
    now.getSeconds()
  ).padStart(2, '0')}`;

  const requestBody = {
    date: localDate, // ë¡œì»¬ íƒ€ì„ìœ¼ë¡œ ë³€í™˜í•œ ë‚ ì§œì™€ ì‹œê°„
    product_id: fileName, // íŒŒì¼ëª…ì„ product_idë¡œ ë³´ëƒ„
    text: ocrText, // OCR ê²°ê³¼ë¥¼ ocr_textë¡œ ë³´ëƒ„
  };

  try {
    const response = await fetch(CONFIG.WORKFLOW_URL, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify(requestBody),
    });

    if (response.ok) {
      console.log('WORKFLOWì— OCR ê²°ê³¼ ì „ë‹¬ ì™„ë£Œ');
    } else {
      console.log('WORKFLOWì— OCR ê²°ê³¼ ì „ë‹¬ ì‹¤íŒ¨:', response.statusText);
    }
  } catch (error) {
    console.log('WORKFLOW OCR ê²°ê³¼ ì „ë‹¬ ì‹¤íŒ¨:', error);
  }
}
